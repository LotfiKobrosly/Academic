{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import Isomap as isomap\n",
    "from mpl_toolkits import mplot3d as plt3d\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I- Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I-1 : Normalizing fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralize(A):\n",
    "    means = np.mean(A, axis=0)\n",
    "    return(A - means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(A,C):\n",
    "    h,w = np.shape(A)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            A[i][j] = A[i][j] / sqrt(C[j][j])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I-2 : PCA function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(cloud,b):\n",
    "    \n",
    "    #Getting the necessary information of the data set \n",
    "    n,d = np.shape(cloud)\n",
    "    \n",
    "    #Centralizaion and \n",
    "    cloud = centralize(cloud)\n",
    "    cloud_t = np.transpose(cloud)\n",
    "    \n",
    "    #Covariance\n",
    "    C = (1/n)*np.dot(cloud_t,cloud)\n",
    "    \n",
    "    #Normalization?\n",
    "    if b:\n",
    "        normalize(cloud,C)\n",
    "        cloud_t = np.transpose(cloud)\n",
    "        C = (1/n) * np.dot(cloud_t,cloud)\n",
    "    \n",
    "    \n",
    "    #Diagnolization\n",
    "    eigenv, eigenvect = np.linalg.eig(C)\n",
    "    \n",
    "    #Ordening\n",
    "    sorted_indexes = np.argsort(eigenv) #first step to sort the eigen vectors matrix\n",
    "    sorted_indexes = sorted_indexes[::-1] #flipping the order, because it is increasing here\n",
    "    \n",
    "    #initializing output\n",
    "    eigenv_sorted = np.zeros((d, 1))\n",
    "    eigenvect_sorted = np.zeros((d,d))\n",
    "    \n",
    "    #sorting the outputs\n",
    "    for i in range(d):\n",
    "        k = sorted_indexes[i]\n",
    "        eigenv_sorted[k] = eigenv[i]\n",
    "        eigenvect_sorted[:,k] = eigenvect[:,i]\n",
    "        \n",
    "    new_coord = np.dot(cloud, np.transpose(eigenvect_sorted)) #Matrix of new coordinates\n",
    "    cumsumvar = np.cumsum(eigenv_sorted[:]) #Vector of cumulated variances\n",
    "    \n",
    "    return ([new_coord, eigenvect_sorted, cumsumvar, eigenv_sorted])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I-3 : MDS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-7-1829631f2c82>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-1829631f2c82>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def mds(cloud, b):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II- Testing on available data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II-1 : Decathlon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and preprocessing decathlon.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"decathlon.dat\", \"r\") as decatfile:\n",
    "    decatrows = csv.reader(decatfile, delimiter = \" \")\n",
    "    decatdata = [] #Array containing decathlon.data entries\n",
    "    decatnames = []\n",
    "    i = 0\n",
    "    for row in decatrows:\n",
    "        if (i>0): #to skip the line defining attributes\n",
    "            decatnames.append(row.pop(0)) #Removing the names from the data set and putting them elsewhere\n",
    "            row[0], row[4], row[9] = '-'+row[0], '-'+row[4], '-'+row[9] #negating the running results\n",
    "            l = row[:] #creating a copy to prevent pointers issues\n",
    "            decatdata.append(l)\n",
    "        else:\n",
    "            events = row[:]\n",
    "        i += 1\n",
    "        \n",
    "decatdata = np.array(decatdata).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA to decathlon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decat_new_coord, decat_new_var, decat_cumsum_var, decat_spect = pca(decatdata, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting PCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.43091499e-03 -3.40953259e-02  2.70101651e-02  9.26963230e-02\n",
      "  -2.06347497e-01 -6.63259253e-02 -1.82211386e-01 -1.26809922e-01\n",
      "  -4.84266538e-01 -8.11627403e-01  1.36245402e-04]\n",
      " [-9.08701654e-04  6.59420253e-03 -2.16842406e-02 -4.12288450e-02\n",
      "   3.19924061e-02  8.83523908e-02  1.09175036e-01 -4.85709292e-01\n",
      "  -7.12890378e-01  4.55695843e-01  1.58908503e-01]\n",
      " [-1.77861301e-03  9.42257382e-03  1.12252116e-01  1.70255161e-01\n",
      "   5.61637060e-02 -9.44638443e-01  2.36321564e-01 -3.64987177e-02\n",
      "  -2.25161097e-02  5.17890510e-02  4.95522450e-02]\n",
      " [-2.52713060e-04  2.70163855e-03 -6.27102650e-03 -8.71622570e-03\n",
      "   1.37187218e-02  2.70135914e-02 -5.88646900e-02 -3.45408542e-02\n",
      "   1.76966903e-01 -9.38268790e-02  9.76821637e-01]\n",
      " [ 6.29567266e-03 -1.50353216e-01  7.68734939e-02  3.57486868e-01\n",
      "  -7.91281195e-01  1.36015585e-01  4.24981106e-01 -1.72840834e-02\n",
      "   9.69491925e-02  8.92242634e-02  2.74575306e-02]\n",
      " [-1.92428952e-03  5.10757433e-02 -2.86961709e-02 -1.48584083e-01\n",
      "   3.65455386e-01  1.86628071e-01  8.43254879e-01  5.65754330e-02\n",
      "  -4.63184455e-02 -2.98749473e-01  2.05662987e-02]\n",
      " [-5.37905969e-03  4.08725084e-02  2.97136475e-01  8.40164300e-01\n",
      "   4.01747123e-01  1.97118852e-01 -5.93791308e-02 -3.79883226e-03\n",
      "  -1.57924015e-02  9.21575382e-03 -1.76986879e-03]\n",
      " [-6.01133661e-04 -1.01391047e-03 -1.33545358e-03  1.88731451e-02\n",
      "  -4.83917322e-02 -7.61372665e-03 -4.61496641e-03  8.61356285e-01\n",
      "  -4.62184433e-01  1.57323623e-01  1.30076068e-01]\n",
      " [-7.55366465e-03  2.95447570e-02  9.43565552e-01 -3.20972530e-01\n",
      "  -5.57401954e-02  4.92202566e-02 -1.06312166e-02  1.96777816e-03\n",
      "  -3.49322680e-03  7.80125853e-03  3.34259024e-03]\n",
      " [ 3.52308439e-02 -9.84694208e-01  2.76667779e-02 -3.89092627e-02\n",
      "   1.62841097e-01 -7.50942270e-03 -1.47961836e-02  5.29000281e-03\n",
      "  -5.25767708e-03  2.75015196e-03  9.95734016e-04]\n",
      " [-9.99311260e-01 -3.62760907e-02 -7.35575653e-03 -1.07163555e-03\n",
      "  -2.08788491e-03  3.03425139e-04  1.68807106e-04 -2.10119308e-04\n",
      "   8.54201974e-04 -6.13860869e-04 -4.05027292e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(decat_new_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II-2: NBA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing an preprocessing NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NBA.dat\",'r') as nbafile:\n",
    "    nbarows = csv.reader(nbafile, delimiter = \" \")\n",
    "    nbadata = []\n",
    "    players = [] #Storing players names, teams and positions\n",
    "    performances = [] #Storing the names of the criteria\n",
    "    i = 0\n",
    "    for row in nbarows:\n",
    "        if (i == 0):\n",
    "            performances = row[:]\n",
    "        else:\n",
    "            name = [row.pop(0)]\n",
    "            players.append(name)\n",
    "            players[i-1].append(row.pop(4))\n",
    "            players[i-1].append(row.pop(4))\n",
    "            nbadata.append(row)\n",
    "        i += 1\n",
    "    nbadata = np.array(nbadata).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA to NBA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_new_coord, nba_new_car, nba_cumsumvar, nba_spect = pca(nbadata,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II-3: Swiss_Roll data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing swiss_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"swiss_roll.dat\",'r') as swissfile:\n",
    "    swissrows = csv.reader(swissfile, delimiter = \" \")\n",
    "    swissdata = []\n",
    "    for row in swissrows:\n",
    "        swissdata.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to a numeric array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "swissdata = np.array(swissdata).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA to swiss_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0.]\n",
      "[0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.99247046,  2.50398539, -8.10575563],\n",
       "       [ 2.71517979,  2.3948333 , -6.90831084],\n",
       "       [ 1.97135171,  2.16023868, -6.25492136],\n",
       "       ...,\n",
       "       [-5.50210824,  1.50402336, -5.77223423],\n",
       "       [ 1.17859885,  2.68887073, -9.13424131],\n",
       "       [-5.97004172,  0.3657981 , -7.01204499]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca(swissdata, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
